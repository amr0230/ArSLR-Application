# ArSLR-Application
> ArSLR Application  ==>  Arabic Alphabet Sign Language Recognition Based on Machine Learning Methods

# Abstract

> There are several groups in society that have different disabilities, such as deaf and dumb groups, that cannot communicate freely with others. The world of deaf and dumb, a world not far away from us but a mysterious world not known to many, and although they are among us, the misperception of society about their world, their movements and body language among them, signs and symbolic expressions that few people understand and are unknown by many people, have led them to isolate themselves from people. So, the main objective of the associations and institutions that sponsor these groups is how to integrate them into society. Therefore, the development of a computerized system that analyzes deaf and dumb signals will help this group and ordinary people to communicate.

> My project aims to recognize the gestures of the 28 characters of the Arabic alphabet. The development and implementation of the proposed system are generally based on two main phases that includes: preprocessing and extracting the necessary features using a machine learning algorithm, which will be used to perform the classification process. In this project, I proposed to use the Support Vector Machine (SVM) and the K-Nearest Neighbors (KNN) classifiers to classify and recognize the gestures of the 28 Arabic letters.
In total, around 14,000 samples of the 28 Arabic alphabetic signs have been used after resizing for the learning and testing phases. The classification process was conducted using a SVM and KNN and achieved an overall accuracy of 89.29% and 83.57% respectively, showing that the results of SVM outperformed those results obtained by KNN. This model also achieved a sensitivity of 89% and 84% for the SVM and KNN respectively.

# Project Objectives:
> - To develop an intelligent computerized system that addresses the problem of ArSLR and based on machine learning algorithms, such as SVM and KNN algorithms.
> - To help people with disabilities such as deaf and dumb to communicate with ordinary people easily and freely, and vice versa.

# Dataset
> The first step is to collect dataset for the 28 Arabic alphabet signs. We need a lot images for each alphabet, this dataset is somewhat hard to collect but thank for University Malaysia Sarawak, Prince Mohammad Bin Fahd University for their dataset. They made a fully labeled dataset consists of 54,049 images of ArSLR alphabets performed by more than 40 volunteers for 32 standard Arabic signs and alphabets (as shown in the picture below).

![image](https://user-images.githubusercontent.com/65462055/169630880-592dc17a-84fb-4d86-8f01-7449dbe24908.png)

# System Interfaces

> ## Login Interface:

![Login](https://user-images.githubusercontent.com/65462055/169636082-267f3e6f-92cd-4117-bd26-0291dcdaa20a.png)

> ## Registration Interface:

![Registration](https://user-images.githubusercontent.com/65462055/169636111-7744c23d-327d-4efd-a2ed-6139edc92a7e.png)

> ## Hand Sign Recognition Interface:

![Applicaiton_Interface](https://user-images.githubusercontent.com/65462055/169636173-155ac464-3ae4-4560-8b70-4142382837eb.png)

![Predict](https://user-images.githubusercontent.com/65462055/169636175-78b18bc6-3fad-4696-8fba-cb0772f5d802.png)





